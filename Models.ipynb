{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from collections import defaultdict\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "uKeys = ['username', 'userId', 'name', 'tags', 'followers', 'following', 'bio', 'followerCount', 'followCount', 'postCount', 'posts', 'recommends']\n",
    "pKeys = [\"id\", \"clapCount\", \"wordCount\", \"readingTime\", \"tags\", \"title\", \"userId\", \"time\", \"subtitle\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readCSV(filename, keys):\n",
    "    objects = []\n",
    "    \n",
    "    with open(filename) as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "        line_count = 0\n",
    "        \n",
    "        for row in csv_reader:\n",
    "            if line_count == -1:\n",
    "                print(f'Column names are {\", \".join(row)}')\n",
    "                line_count += 1\n",
    "            else:\n",
    "\n",
    "                u = {}\n",
    "                for i,k in enumerate(keys): \n",
    "                    u[k] = row[i]\n",
    "                objects.append(u)\n",
    "\n",
    "                line_count += 1\n",
    "                \n",
    "    print(f'Processed {line_count} lines.')\n",
    "    return objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4131 lines.\n"
     ]
    }
   ],
   "source": [
    "readUsers = readCSV('users.csv', uKeys)\n",
    "users = defaultdict(dict)\n",
    "\n",
    "for u in readUsers:\n",
    "    users[u['userId']] = u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 25163 lines.\n"
     ]
    }
   ],
   "source": [
    "readPosts = readCSV('posts.csv', pKeys)\n",
    "posts = defaultdict(dict)\n",
    "\n",
    "for p in readPosts:\n",
    "    posts[p['id']] = p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3544"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20265"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "testUsers = list(users.keys())\n",
    "testPosts_ = [ast.literal_eval(users[u]['recommends']) for u in testUsers]\n",
    "testPosts = []\n",
    "for arr in testPosts_:\n",
    "    for p in arr: testPosts.append(p)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11521"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "testPosts = list(set(testPosts))\n",
    "random.shuffle(testPosts)\n",
    "len(testPosts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = np.zeros((len(testUsers), len(testPosts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = []\n",
    "for i,u in enumerate(testUsers):\n",
    "    for j,p in enumerate(testPosts):\n",
    "        if p in ast.literal_eval(users[u]['recommends']):\n",
    "            matrix[i][j] = 1\n",
    "            pairs.append((i,j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "### randomly remove some user-article claps\n",
    "### maintain list and compare with output\n",
    "len(pairs)\n",
    "random.shuffle(pairs)\n",
    "hidden_claps = pairs[int(len(pairs) * 0.9):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1355"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hidden_claps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide claps\n",
    "for (i,j) in hidden_claps:\n",
    "    matrix[i][j] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneClassRecommendation():\n",
    "\n",
    "    def __init__(self, R, K, alpha, beta, iterations):\n",
    "        \"\"\"\n",
    "        Perform matrix factorization to predict empty\n",
    "        entries in a matrix.\n",
    "\n",
    "        Arguments\n",
    "        - R (ndarray)   : user-item rating matrix\n",
    "        - K (int)       : number of latent dimensions\n",
    "        - alpha (float) : learning rate\n",
    "        - beta (float)  : regularization parameter\n",
    "        \"\"\"\n",
    "\n",
    "        self.R = R\n",
    "        self.num_users, self.num_items = R.shape\n",
    "        self.K = K\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.iterations = iterations\n",
    "\n",
    "    def train(self):\n",
    "        # Initialize user and item latent feature matrice\n",
    "        self.gamma_u = np.random.normal(scale=1./self.K, size=(self.num_users, self.K))\n",
    "        self.gamma_i = np.random.normal(scale=1./self.K, size=(self.num_items, self.K))\n",
    "\n",
    "        # Initialize the biases\n",
    "        self.b_u = np.zeros(self.num_users)\n",
    "        self.b_i = np.zeros(self.num_items)\n",
    "        self.b = np.mean(self.R[np.where(self.R != 0)])\n",
    "\n",
    "        # Create a list of training samples\n",
    "#         self.samples = [\n",
    "#             (i, j, self.R[i, j])\n",
    "#             for i in range(self.num_users)\n",
    "#             for j in range(self.num_items)\n",
    "#             if self.R[i, j] > 0\n",
    "#         ]\n",
    "\n",
    "        # sample user, article-clapped and article-not-clapped\n",
    "        self.samples = [] # u, i, j\n",
    "        for u in range(self.num_users):\n",
    "            claps = []\n",
    "            non_claps = []\n",
    "            \n",
    "            for i in range(self.num_items):\n",
    "                if self.R[u][i] == 1:\n",
    "                    claps.append(i)\n",
    "                else:\n",
    "                    non_claps.append(i)\n",
    "            \n",
    "            random.shuffle(non_claps)\n",
    "            non_claps[:len(claps)]\n",
    "            \n",
    "            for i in range(len(claps)):\n",
    "                self.samples.append((u, claps[i], non_claps[i]))\n",
    "\n",
    "        # Perform stochastic gradient descent for number of iterations\n",
    "        training_process = []\n",
    "        for i in range(self.iterations):\n",
    "            np.random.shuffle(self.samples)\n",
    "            gain = self.sga()\n",
    "#             mse = self.mse()\n",
    "            training_process.append((i, gain))\n",
    "            if (i+1) % 10 == 0:\n",
    "                print(\"Iteration: %d ; gain = %.4f\" % (i+1, gain))\n",
    "\n",
    "        return training_process\n",
    "\n",
    "    def mse(self):\n",
    "        \"\"\"\n",
    "        A function to compute the total mean square error\n",
    "        \"\"\"\n",
    "        xs, ys = self.R.nonzero()\n",
    "        predicted = self.full_matrix()\n",
    "        error = 0\n",
    "        for x, y in zip(xs, ys):\n",
    "            error += pow(self.R[x, y] - predicted[x, y], 2)\n",
    "        return np.sqrt(error)\n",
    "\n",
    "    def dot(self, K, L):\n",
    "        \"\"\"\n",
    "        A function to compute the dot product of two lists\n",
    "        \"\"\"\n",
    "        if len(K) != len(L):\n",
    "            return 0\n",
    "        \n",
    "        return sum(i[0] * i[1] for i in zip(K, L))\n",
    "    \n",
    "    def sga(self):\n",
    "        \"\"\"\n",
    "        Perform stochastic graident ascent\n",
    "        \"\"\"\n",
    "        gain = 0\n",
    "        \n",
    "        for u, i, j in self.samples:\n",
    "            # Compute gradient\n",
    "            dot_prod = self.dot(self.gamma_u[u], self.gamma_i[i]) - self.dot(self.gamma_u[u], self.gamma_i[j])\n",
    "            exp_sum = math.exp(-1*dot_prod)\n",
    "            \n",
    "            for k in range(self.K):\n",
    "                gr = (self.gamma_i[i][k] - self.gamma_i[j][k]) * (exp_sum) / (1 + exp_sum)\n",
    "\n",
    "                # Update biases\n",
    "                self.b_u[u] += self.alpha * (gr - self.beta * self.b_u[u])\n",
    "                self.b_i[i] += self.alpha * (gr - self.beta * self.b_i[i])\n",
    "                self.b_i[j] += self.alpha * (gr - self.beta * self.b_i[j])\n",
    "\n",
    "                # Update user and item latent feature matrices\n",
    "                self.gamma_u[u][k] += self.alpha * (gr - self.beta * sum(self.gamma_u[u]))\n",
    "                self.gamma_i[i][k] += self.alpha * (gr - self.beta * sum(self.gamma_i[i]))\n",
    "                self.gamma_i[j][k] += self.alpha * (gr - self.beta * sum(self.gamma_i[j]))\n",
    "            \n",
    "    \n",
    "            gain +=  sigmoid(dot_prod)\n",
    "        \n",
    "        return gain / len(self.samples)\n",
    "\n",
    "    def get_rating(self, u, i):\n",
    "        \"\"\"\n",
    "        Get the predicted rating of user u and item i\n",
    "        \"\"\"\n",
    "        prediction = self.b + self.b_u[u] + self.b_i[i] + self.gamma_u[u].dot(self.gamma_i[i].T)\n",
    "        return prediction \n",
    "\n",
    "    def full_matrix(self):\n",
    "        \"\"\"\n",
    "        Computer the full matrix using the resultant biases, P and Q\n",
    "        \"\"\"\n",
    "        return self.b + self.b_u[:,np.newaxis] + self.b_i[np.newaxis:,] + self.gamma_u.dot(self.gamma_i.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf = OneClassRecommendation(matrix, K=100, alpha=0.1, beta=0.01, iterations=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.OneClassRecommendation at 0x1295ade48>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mf.R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10 ; gain = 0.5098\n",
      "Iteration: 20 ; gain = 0.5300\n",
      "Iteration: 30 ; gain = 0.5543\n",
      "Iteration: 40 ; gain = 0.5836\n",
      "Iteration: 50 ; gain = 0.6176\n",
      "Iteration: 60 ; gain = 0.6546\n",
      "Iteration: 70 ; gain = 0.6910\n",
      "Iteration: 80 ; gain = 0.7236\n",
      "Iteration: 90 ; gain = 0.7512\n",
      "Iteration: 100 ; gain = 0.7740\n",
      "Iteration: 110 ; gain = 0.7926\n",
      "Iteration: 120 ; gain = 0.8081\n",
      "Iteration: 130 ; gain = 0.8208\n",
      "Iteration: 140 ; gain = 0.8310\n",
      "Iteration: 150 ; gain = 0.8391\n",
      "Iteration: 160 ; gain = 0.8456\n",
      "Iteration: 170 ; gain = 0.8507\n"
     ]
    }
   ],
   "source": [
    "mf.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = set(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err = corr = 0\n",
    "THRESH = 0.8\n",
    "for i in range(len(matrix)):\n",
    "    for j in range(len(matrix[0])):\n",
    "        if matrix[i][j] == 0: continue\n",
    "        if matrix[i][j] == 1 and (i,j) not in pairs and mf.get_rating(i, j) > THRESH:\n",
    "            corr += 1\n",
    "        else:\n",
    "            err += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training accuracy\n",
    "corr / (corr + err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = err = 0\n",
    "for (i,j) in pairs:\n",
    "    if mf.get_rating(i,j) > THRESH:\n",
    "        corr += 1\n",
    "    else:\n",
    "        err += 1\n",
    "\n",
    "corr / (corr + err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3990, 5929, 9058]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in range(len(matrix[0])) if matrix[0][i] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.218833184504723"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train_validate(testUsers, testPosts):\n",
    "    num_claps = 0\n",
    "    for u in testUsers:\n",
    "        for p in testPosts:\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
