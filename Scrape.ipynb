{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "import json\n",
    "import csv\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "MEDIUM = \"https://medium.com/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_json_response(response):\n",
    "    return json.loads(response.text.split('])}while(1);</x>')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://medium.com/_/api/users/af97a6a078cf/profile/stream?limit=100&source=followers\"\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "req = urllib.request.Request(url, headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with urllib.request.urlopen(req) as response:\n",
    "    the_page = response.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = (str(the_page).split(\"</x>\")[1])[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "import re\n",
    "s = literal_eval(\"'%s'\" % s)\n",
    "# re.sub(r'http\\S+', \"\", s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "j =json.loads(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Politics', 261302),\n",
       " ('Marketing', 171362),\n",
       " ('Writing', 169430),\n",
       " ('Humor', 80623),\n",
       " ('Books', 69728),\n",
       " ('Creativity', 66016),\n",
       " ('Environment', 49420),\n",
       " ('Climate Change', 39734),\n",
       " ('College', 32550),\n",
       " ('Interview', 28916),\n",
       " ('Satire', 22657),\n",
       " ('Reading', 22609),\n",
       " ('Creative Writing', 22563),\n",
       " ('Comedy', 22205),\n",
       " ('Writing Tips', 14114),\n",
       " ('Publishing', 12506),\n",
       " ('Flash Fiction', 10560),\n",
       " ('Essay', 10290),\n",
       " ('Activism', 9644),\n",
       " ('Grief', 8670),\n",
       " ('Nonfiction', 8151),\n",
       " ('Poverty', 7199),\n",
       " ('Authors', 5971),\n",
       " ('Novel', 5902),\n",
       " ('Capitalism', 5100),\n",
       " ('Protest', 5041),\n",
       " ('Creative Process', 5024),\n",
       " ('Florida', 4513),\n",
       " ('Writing Life', 4287),\n",
       " ('Fishing', 4032),\n",
       " ('Classics', 2789),\n",
       " ('Pitching', 2596),\n",
       " ('Editing', 2478),\n",
       " ('Personal Essay', 2008),\n",
       " ('Fathers', 1950),\n",
       " ('Lawsuit', 1626),\n",
       " ('Hurricane', 1358),\n",
       " ('Readinglist', 1277),\n",
       " ('MFA', 1107),\n",
       " ('Writing Advice', 238),\n",
       " ('Hurricane Florence', 99)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(d['name'], d['postCount']) for d in j['payload']['userMeta']['authorTags']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = j['payload']['streamItems'][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "followers = [u['userPreview']['userId'] for u in f]\n",
    "len(followers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.parse\n",
    "\n",
    "def parseResponse(url, args):\n",
    "    params = urllib.parse.urlencode(args)\n",
    "    \n",
    "    if len(args) != 0:\n",
    "        url = url + '?%s' % params\n",
    "    \n",
    "    req = urllib.request.Request(url, headers=headers)\n",
    "    \n",
    "    with urllib.request.urlopen(req) as response:\n",
    "        the_page = response.read()\n",
    "        \n",
    "    s = (str(the_page).split(\"</x>\")[1])[:-1]\n",
    "    s = literal_eval(\"'%s'\" % s)\n",
    "    \n",
    "    j = json.loads(s)\n",
    "    \n",
    "    return j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFollowers(userId):\n",
    "    print(\"Fetching user followers...\")\n",
    "    \n",
    "    followers = set([])\n",
    "    limit = 20\n",
    "    hard_cap = 1000\n",
    "    \n",
    "    url = \"https://medium.com/_/api/users/\" + userId + \"/profile/stream?limit=\"+str(limit)+\"&source=followers\"\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    j = clean_json_response(response)\n",
    "    j = j['payload']\n",
    "    \n",
    "    total = j['references']['SocialStats'][userId]['usersFollowedByCount']\n",
    "    \n",
    "    count = 0\n",
    "    print(\"total = \" + str(total))\n",
    "    \n",
    "    while 'next' in j['paging'] and limit*count <= min(total, hard_cap):\n",
    "        \n",
    "        # add new users to followers set\n",
    "        f = j['streamItems'][1:]\n",
    "        f = [u['userPreview']['userId'] for u in f]\n",
    "        for u in f: followers.add(u)\n",
    "        \n",
    "        # end of pagination check\n",
    "        if 'to' not in j['paging']['next']: \n",
    "            break\n",
    "        \n",
    "        # find next page from response\n",
    "        next_url = j['paging']['path']\n",
    "        next_params = j['paging']['next']\n",
    "        \n",
    "        # parse next page\n",
    "        response = requests.get(next_url, next_params)\n",
    "        j = clean_json_response(response)\n",
    "        j = j['payload']\n",
    "        \n",
    "        count += 1\n",
    "    \n",
    "    return list(followers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFollowing(userId):\n",
    "    print(\"Fetching user following...\")\n",
    "    \n",
    "    following = set([])\n",
    "    limit = 20\n",
    "    hard_cap = 1000\n",
    "    \n",
    "    url = \"https://medium.com/_/api/users/\" + userId + \"/profile/stream?limit=\"+str(limit)+\"&source=following\"\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    j = clean_json_response(response)\n",
    "    j = j['payload']\n",
    "    \n",
    "    total = j['references']['SocialStats'][userId]['usersFollowedCount']\n",
    "    \n",
    "    count = 0\n",
    "    print(\"total = \" + str(total))\n",
    "    \n",
    "    while 'next' in j['paging'] and limit*count <= min(total, hard_cap):\n",
    "        \n",
    "        # add new users to followers set\n",
    "        f = j['streamItems'][1:]\n",
    "        f = [u['userPreview']['userId'] for u in f]\n",
    "        for u in f: following.add(u)\n",
    "        \n",
    "        # end of pagination check\n",
    "        if 'to' not in j['paging']['next']: \n",
    "            break\n",
    "        \n",
    "        # find next page from response\n",
    "        next_url = j['paging']['path']\n",
    "        next_params = j['paging']['next']\n",
    "        \n",
    "        # parse next page\n",
    "        response = requests.get(next_url, next_params)\n",
    "        j = clean_json_response(response)\n",
    "        j = j['payload']\n",
    "        \n",
    "        count += 1\n",
    "    \n",
    "    return list(following)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parsePostsPayload(payload, userId):\n",
    "    if 'references' not in payload or 'Post' not in payload['references']: return []\n",
    "    \n",
    "    postIds = [k for k in payload['references']['Post']]\n",
    "    \n",
    "    posts = [] # post objects\n",
    "    for pid in postIds:\n",
    "        postObj = payload[\"references\"][\"Post\"][pid]\n",
    "        \n",
    "        # filter out responses from claps list            \n",
    "        if postObj['virtuals']['readingTime'] < 1: continue\n",
    "        \n",
    "        if len(postObj['virtuals']['tags']) == 0 and len(postObj['virtuals']['subtitle']) == 0:\n",
    "            continue\n",
    "        \n",
    "        newObj = {'id': pid}\n",
    "        \n",
    "        newObj['clapCount'] = postObj['virtuals']['totalClapCount']\n",
    "        newObj['wordCount'] = postObj['virtuals']['wordCount']\n",
    "        newObj['readingTime'] = postObj['virtuals']['readingTime']\n",
    "        newObj['tags'] = [tag['name'] for tag in postObj['virtuals']['tags']]\n",
    "        newObj['title'] = postObj['title']\n",
    "        newObj['userId'] = postObj['creatorId']\n",
    "        newObj['time'] = postObj['latestPublishedAt']\n",
    "        newObj['subtitle'] = postObj['virtuals']['subtitle']\n",
    "        \n",
    "        posts.append(newObj)\n",
    "    \n",
    "    return posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape page to get clapped posts\n",
    "def getClaps(username, userId):\n",
    "    print(\"Getting user claps...\")\n",
    "    \n",
    "    url = MEDIUM + \"@\" + username + \"/has-recommended?format=json\"\n",
    "\n",
    "    response = requests.get(url)\n",
    "    response_dict = clean_json_response(response)\n",
    "    \n",
    "    payload = response_dict['payload']\n",
    "    items = payload['streamItems']\n",
    "    \n",
    "    posts = parsePostsPayload(payload, userId) \n",
    "    \n",
    "    filtered_posts = posts[:]\n",
    "    for p in posts:\n",
    "        if p['userId'] == userId:\n",
    "            filtered_posts.remove(p)\n",
    "    \n",
    "    print('done')\n",
    "    \n",
    "    return filtered_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getUserPosts(username, userId):\n",
    "\n",
    "    print('Retrieving the latest posts...')\n",
    "\n",
    "    post_ids = []\n",
    "    \n",
    "    url = MEDIUM + '@' + username + '/latest?format=json'\n",
    "    response = requests.get(url)\n",
    "    response_dict = clean_json_response(response)\n",
    "    \n",
    "    try:\n",
    "        posts = response_dict['payload']['references']['Post']\n",
    "    except:\n",
    "        return []\n",
    "    \n",
    "    payload = response_dict['payload']\n",
    "    posts = parsePostsPayload(payload, userId)\n",
    "    \n",
    "    print('done')\n",
    "    \n",
    "    return posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting user claps...\n",
      "done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'id': '4ccbfbb14314',\n",
       "  'clapCount': 11,\n",
       "  'wordCount': 1394,\n",
       "  'readingTime': 5.960377358490566,\n",
       "  'tags': ['Work', 'Work Life Balance', 'Anxiety', 'Advice'],\n",
       "  'title': 'Ten Ways to Thrive in a Corporate Job if you have Anxiety',\n",
       "  'userId': 'bb51e8f2c528',\n",
       "  'time': 1542405250600,\n",
       "  'subtitle': 'The corporate world can be intimidating, especially when you’re first starting out. Add to that a pounding heart or nagging stream of…'},\n",
       " {'id': 'e1b39c8c38ea',\n",
       "  'clapCount': 1984,\n",
       "  'wordCount': 1546,\n",
       "  'readingTime': 5.833962264150943,\n",
       "  'tags': ['Facebook', 'Social Media'],\n",
       "  'title': 'The Definitive Tactical Guide to Quitting Facebook',\n",
       "  'userId': 'eb358f417ed6',\n",
       "  'time': 1541514661500,\n",
       "  'subtitle': 'How to cover all your bases before leaving the site for good'},\n",
       " {'id': '7898ab6bc23e',\n",
       "  'clapCount': 270,\n",
       "  'wordCount': 2213,\n",
       "  'readingTime': 9.050943396226414,\n",
       "  'tags': ['Politics',\n",
       "   'Elections',\n",
       "   'Election 2018',\n",
       "   'Donald Trump',\n",
       "   'Equality'],\n",
       "  'title': 'Yes, I Voted. I Hope You Vote, Too.',\n",
       "  'userId': '7973075212bc',\n",
       "  'time': 1541556685907,\n",
       "  'subtitle': 'One apolitical man finds his voice at the midterm election. Perhaps I can help you find yours, too.'}]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(getClaps('RebeccaRennerFL', 'af97a6a078cf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getUser(userId):\n",
    "    url = \"https://medium.com/_/api/users/\" + userId + \"/profile/stream?limit=25&source=followers\"\n",
    "    \n",
    "    response = requests.get(url)\n",
    "    j = clean_json_response(response)\n",
    "    j = j['payload']\n",
    "    \n",
    "    f = j['streamItems'][1:]\n",
    "    \n",
    "    user = {}\n",
    "    user['username'] = j['user']['username']\n",
    "    user['userId'] = j['user']['userId']\n",
    "    user['name'] = j['user']['name']\n",
    "    user['tags'] = [tag['name'] for tag in j['userMeta']['authorTags']]\n",
    "    user['followers'] = getFollowers(userId)\n",
    "    user['following'] = getFollowing(userId)\n",
    "    user['bio'] = j['user']['bio']\n",
    "    user['followerCount'] = j['references']['SocialStats'][userId]['usersFollowedByCount']\n",
    "    user['followCount'] = j['references']['SocialStats'][userId]['usersFollowedCount']\n",
    "    user['postCount'] = j['userMeta']['numberOfPostsPublished']\n",
    "    \n",
    "    userPosts = getUserPosts(user['username'], userId) # list of post objects\n",
    "    user['posts'] = [p['id'] for p in userPosts] # list of pospt ids\n",
    "    \n",
    "    userClaps = getClaps(user['username'], userId)\n",
    "    user['recommends'] = [p['id'] for p in userClaps] # list of post objects that user has clapped on\n",
    "    \n",
    "    return user, userPosts+userClaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching user followers...\n",
      "total = 2277\n",
      "Fetching user followers...\n",
      "total = 2277\n",
      "Retrieving the latest posts...\n",
      "done\n",
      "Getting user claps...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "startId = \"af97a6a078cf\"\n",
    "startUser, posts = getUser(startId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def get_list_of_latest_posts_ids(usernames):\n",
    "\n",
    "    print('Retrieving the latest posts...')\n",
    "\n",
    "    post_ids = []\n",
    "    \n",
    "    for username in usernames:\n",
    "        url = MEDIUM + '/@' + username + '/latest?format=json'\n",
    "        response = requests.get(url)\n",
    "        response_dict = clean_json_response(response)\n",
    "        \n",
    "        try:\n",
    "            posts = response_dict['payload']['references']['Post']\n",
    "        except:\n",
    "            posts = []\n",
    "\n",
    "        if posts:\n",
    "            for key in posts.keys():\n",
    "                post_ids.append(posts[key]['id'])\n",
    "\n",
    "    return post_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_post_responses(posts):\n",
    "\n",
    "    print('Retrieving the post responses...')\n",
    "\n",
    "    responses = []\n",
    "\n",
    "    for post in posts:\n",
    "        url = MEDIUM + '/_/api/posts/' + post + '/responses'\n",
    "        response = requests.get(url)\n",
    "        response_dict = clean_json_response(response)\n",
    "        responses += response_dict['payload']['value']\n",
    "\n",
    "    return responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_high_recommends(response, recommend_min):\n",
    "    if response['virtuals']['recommends'] >= recommend_min:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "def check_if_recent(response):\n",
    "    limit_date = datetime.now() - timedelta(days=30)\n",
    "    creation_epoch_time = response['createdAt'] / 1000\n",
    "    creation_date = datetime.fromtimestamp(creation_epoch_time)\n",
    "\n",
    "    if creation_date >= limit_date:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_ids_from_responses(responses, recommend_min):\n",
    "\n",
    "    print('Retrieving user IDs from the responses...')\n",
    "\n",
    "    user_ids = []\n",
    "\n",
    "    for response in responses:\n",
    "        recent = check_if_recent(response)\n",
    "        high = check_if_high_recommends(response, recommend_min)\n",
    "\n",
    "        if recent or high:\n",
    "            user_ids.append(response['creatorId'])\n",
    "\n",
    "    return user_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# End product:\n",
    "# postId -> postObj\n",
    "# userId -> userObj\n",
    "\n",
    "# userObj -> name, username, followersId, followeesId, postsId, clapsId, categories, bio\n",
    "# postObj -> author, responses, categories, title, time read, clapcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# write header to file\n",
    "f = csv.writer(open(\"users.csv\", 'w'))\n",
    "f.writerow(users[0].keys())\n",
    "\n",
    "g = csv.writer(open(\"posts.csv\", \"w\"))\n",
    "g.writerow(posts[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeUserToFile(filename, u): # append to file\n",
    "    f = csv.writer(open(filename, \"a\"))\n",
    "    f.writerow([u[k] for k in u.keys()])\n",
    "\n",
    "def writePostToFile(filename, p):\n",
    "    f = csv.writer(open(filename, \"a\"))\n",
    "    for post in p:\n",
    "        f.writerow([post[k] for k in post.keys()])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes starting user, limit\n",
    "# returns -> users, post-ids (to be scraped)\n",
    "def scrapeUsers(startId, limit):\n",
    "    users = []\n",
    "    posts = []\n",
    "    \n",
    "    user, p = getUser(startId)\n",
    "    \n",
    "    posts += p\n",
    "    writePostToFile('posts.csv', posts)\n",
    "    users.append(user)\n",
    "    writeUserToFile('users.csv', user)\n",
    "    \n",
    "    while len(users) < limit:\n",
    "        print(\"iter = \" + str(len(users)))\n",
    "        max_f = 0\n",
    "        max_u = None\n",
    "        \n",
    "        for uid in user['following']:\n",
    "            u, p = getUser(uid)\n",
    "            users.append(u)\n",
    "            writePostToFile('posts.csv', p)\n",
    "            writeUserToFile('users.csv', u)\n",
    "            \n",
    "            posts += p\n",
    "        \n",
    "            if u['followerCount'] > max_f:\n",
    "                max_f = u['followerCount']\n",
    "                max_u = u\n",
    "            \n",
    "            if len(users) > limit: break\n",
    "            \n",
    "        user = max_u\n",
    "    \n",
    "    return users, posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching user followers...\n",
      "total = 2277\n",
      "Fetching user following...\n",
      "total = 1266\n",
      "Retrieving the latest posts...\n",
      "done\n",
      "Getting user claps...\n",
      "done\n",
      "iter = 1\n",
      "Fetching user followers...\n",
      "total = 24602\n",
      "Fetching user following...\n",
      "total = 29832\n",
      "Retrieving the latest posts...\n",
      "done\n",
      "Getting user claps...\n",
      "done\n",
      "Fetching user followers...\n",
      "total = 451\n",
      "Fetching user following...\n",
      "total = 1396\n"
     ]
    }
   ],
   "source": [
    "users, posts = scrapeUsers('af97a6a078cf', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
